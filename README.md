# Data-Modeling-with-Postgres

# introduction
- In this project, we will creates a postgres database for a music app, and build an ETL pipeline using Python
  Based on the needs of the analytics team.

  The analytics team is particularly interested in understanding what songs users are listening to. Currently, they don't have an easy way to query their data, which     resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.
  
# How to run 
- opening terminal and execute the following 

1. python create_tables.py
2. python etl.py


# An explanation of the files in the repository 
1. sql_queries.py : contains all sql statements used in this project. 
2. create_tables.py : this file create the database then drop all tables uses drop tables queries in sql_queries.py, then create all tables uses creates queries in sql_queries.py.
3. etl.ipynb : A Jupyter Notebook to reads and processes a single file from song_data and log_data and loads the data into the tables.
4. etl.py : Python script to Extract data from the Log and Song data files, processes and inserts data into the database.
5. test.ipynb : Python Jupyter Notebook used to test the project.

# Data 
## Song Dataset
- The first dataset is a subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID. For example, here are file paths to two files in this dataset.
```
song_data/A/B/C/TRABCEI128F424C983.json
song_data/A/A/B/TRAABJL12903CDCF1A.json
```
And below is an example of what a single song file, TRAABJL12903CDCF1A.json, looks like.
```
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}
```
## Log Dataset
The second dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.

The log files in the dataset you'll be working with are partitioned by year and month. For example, here are filepaths to two files in this dataset.
```
log_data/2018/11/2018-11-12-events.json
log_data/2018/11/2018-11-13-events.json
```
And below is an example of what the data in a log file, 2018-11-12-events.json, looks like.
![1](https://user-images.githubusercontent.com/87584678/206748753-a4c6443f-83fc-4a68-97aa-f77c5b4d614d.png)

# Schema Design
![2](https://user-images.githubusercontent.com/87584678/206753447-f63c4c0d-c3ea-4440-b03a-3f9f4c5342a2.PNG)





